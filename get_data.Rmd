---
title: "Obtenção de dados hidrológicos na web"
description: Conceitos básicos
---

```{r setup, include=FALSE}
library(knitr)
library(XML)
library(dplyr)
```

## Repositório de dados

Existem inúmeros repositórios contendo dados hidrológicos no mundo e no Brasil. Alguns exemplos são:

- HidroWeb da ANA;
- Séries históricas do ONS;
- Dados do CPRM;
- Dados do INMET.

## Obtenção de dados "tradicional"

<<<<<<< HEAD
Uma maneira de obter dados hidrológicos é simplesmente acessando de algum site oficial. Geralmente, o arquivo obtido baixado está no formato `.csv`, `.txt` ou `.xls` (excel) - esse último sendo menos comum. No próprio portal da ANA tem a opção de baixar os dados diretamente se souber a estação em questão ou utilizando um mapa dinâmico. Fazemos o exemplo abaixo para a estação 60435000. Ao baixar o arquivo, é importante entender como ele está salvo, para isso podemos abrir o arquivo pelo bloco de notas por exemplo. O arquivo em questão é mostrado na figura abaixo
=======
Uma maneira de obter dados é simplesmente baixando eles de algum site oficial. Geralmente o arquivo baixado está no formato `.csv`, `.txt` ou `.xls` (excel) - esse último sendo menos comum. No próprio portal da ANA tem a opção de baixar os dados diretamente se souber a estação em questão (https://www.snirh.gov.br/hidroweb/serieshistoricas) ou utilizando um mapa dinâmico (https://www.snirh.gov.br/hidroweb/mapa). Fazemos o exemplo abaixo para a estação 60435000. Ao baixar o arquivo, é importante entender como ele está salvo, para isso podemos abrir o arquivo pelo bloco de notas por exemplo. O arquivo em questão é mostrado na figura abaixo
>>>>>>> 2aa96fc38fa716a70fee28c186be23697f6320d1

```{r obtencao_dados_trad_imagem_1, echo = FALSE, layout = "l-body-outset", fig.align = 'center', out.width = "100%", fig.cap = ""}
knitr::include_graphics("images/arquivo_vazao_ANA_csv.png")
```

É possível perceber alguns detalhes importantes. As primeiras 13 linhas contém informações sobre o sistema em sí e a estação, mas os dados medidos começam de fato na linha 14. O separador de cada coluna é um "`;`" e os decimais são separados por "`,`". Agora já temos as informações necessárias para acessar esses dados pelo **R**. Usamos aqui a função `read.table()`, também é possível utilizar a função `read.csv()`, ambas fazem a mesma coisa, apenas alteram os argumentos pré definidos (que podem ser trocados).

```{r obtencao_dados_trad_1}
dados_ANA <- read.table(file = "dados/vazoes_T_60435000.txt",
                        skip = 13,
                        header = T,
                        sep = ";",
                        dec = ",")
```

Agora podemos ver quais colunas existem nesse dataframe dentro do próprio **R** e tentar entender ele melhor também!

```{r obtencao_dados_trad_2}
colnames(dados_ANA)
```

A seguir puxaremos o mesmo dado porém diretamente da internet, utilizando o que chamamos de *webservice*. Isso facilita muito a criação de códigos mais automatizados em que não é necessário ficar baixando os dados um a um.

## Obtenção via webservice
Ser capaz de obter informações hidrológicas de forma gratuita diretamente da internet, algo conhecido como "webscraping", representa um ganho significativo de eficiência no desenvolvimento de estudos e projetos de hidrologia, recursos hídricos, e áreas afins.

Essa possibilidade vem se tornando cada vez mais comum nos dias de hoje. Por exemplo, a Agência Nacional de Águas e Saneamento Básico (ANA), o Operador Nacional do Sistema Elétrico (ONS), e outras instituições no Brasil e no exterior disponibilizam alguns de seus dados por meio do chamado webservice. 

Em essência, o webservice é apenas um site que contém os dados. Porém, esses dados estão organizados de uma maneira bem específica, de forma que para que seja possível obtê-los de forma eficiente, é imprescindível que essa organização seja bem entedida. Aqui neste curso introdutório, vamos focar nossas atividades no webservice da ANA, que se encontra disponível por meio do  url <http://telemetriaws1.ana.gov.br/ServiceANA.asmx>.

Quando acessamos esse endereço, somos levados para a página abaixo,

```{r webservice_ANA, echo = FALSE, layout = "l-body-outset", fig.align = 'center', out.width = "100%", fig.cap = ""}
knitr::include_graphics("images/webservice_ANA.png")
```

Se dermos um zoom na figura, podemos verificar todas as informações que estão disponíveis no webservice, tais como "dados hidrometeorológicos", "dados hidrometeorológicos gerais", "lista de estações telemétricas", "Cotas", "inventário", "rios", "série histórica", entre outras. 

Nesse mesmo site, pode-se acessar um arquivo em formato pdf com detalhes sobre o sistema como um todo, e com o que se pode obter dentro dele <http://telemetriaws1.ana.gov.br/Telemetria1ws.pdf>! Esse arquivo é essencial para entendermos como os dados estão disponíveis e como podemos acessá-los.

Esse documento nos informa que os dados hidrológicos da ANA estão disponibilizados no formato XML ("Extended Markup Language"), de forma que precisamos aprender como acessar e manipular as informações disponibilizados nesse formato. Mas discutiremos apenas o básico neste curso, sem nos profundarmos muito. Porém se você deseja saber mais sobre webscraping e usufruir de várias de suas possibilidade, sugerimos que procure se aprofundar mais nesse tema.

Para acessar dados do tipo **XML** dentro do **R**, utilizamos um pacote já criado, chamado **XML**. Lembrando que caso não tenhamos instalado ele ainda, precisamos o fazer com o `install.packages()`. Em seguida precisamos apenas carregar na seção utilizando `library()` como escrito abaixo. Além desse pacote, também utilizaremos algumas partes do pacote **lubridate** para trabalharmos com datas.

```{r instalando_e_baixando_XML}
install.packages("XML")
library(XML)

install.packages("lubridate")
library(lubridate)
```

### Lista das Estações Telemétricas da ANA

Começaremos nossas atividades acessando os dados das estações telemétricas desse sistema. Pode-se perceber olhando para o próprio site, que são necessários dois parâmetros para pesquisar as estações. O primiero chama-se “statusEstacoes”, que pode ser 0, que significa estação ativa, ou 1, que representa estação em manutenção. O segundo parâmetro é chamado de “Origem”, podendo variar entre 0 e 5. Se olharmos o arquivo em formato pdf mencioando acima, vamos ver que se deixarmos o “statusEstacoes” em branco, serão retornadas as informações de todas as estações do sistema, que é exatamente o que queremos agora. 

Sendo assim, se colocarmos no nosso navegador o seguinte url: <http://telemetriaws1.ana.gov.br/ServiceANA.asmx/ListaEstacoesTelemetricas?statusEstacoes=&origem=>, teremos acesso ao arquivo XML com a informação de todas as estações telemétricas.

```{r XML_ANA_info_1, echo = FALSE, fig.align = 'center', out.width = "90%", fig.cap = ""}
knitr::include_graphics("images/XML_ANA_info_1.png")
```

Para que tenhamos cesso a essas informações nesse mesmo formato no RStudio, teremos que fazer uso de um pacote chamado "XML", que contém a função denominada `xmlParse()`. Essa função é capaz de ler um arquivo do tipo XML e gerar uma estrutura no **R** similar ao que aparece na imagem acima (formato de “árvore”). A função exige que informemos um argumento obrigatório, que é o *url* a ser utilizado, e permite ainda que passemos um argumento opcional, que é a codificação do arquivo (do inglês encoding). Usualmente no Brasil, utilizamos o “UTF-8” para poder utilizar nossos acentos (mas lembre-se que essa parte é um outro mundo no R e não entraremos com maiores detalhamentos). Quando um pacote já está carregado dentro do **R**, não precisamos escrever ele antes da função - isso, porém, pode ser uma boa prática para deixar o código mais fácil de ler (uma vez que qualquer leitor entenderia que a funçção ``xmlParse()`` pertence ao pacote **XML** uma vez que está escrito `XML::` antes da função!

```{r XML_no_R_ANA}
status_codigo <- ""
origem_codigo <- ""

url_base <- paste0("http://telemetriaws1.ana.gov.br/ServiceANA.asmx/ListaEstacoesTelemetricas?",
                   "statusEstacoes=", status_codigo, "&origem=", origem_codigo)
url_parse <- XML::xmlParse(url_base, encoding = "UTF-8")
```

Olha o nosso código um pouco. Percebe que invés de digitar diretamente o url para acesso, quebramos ele em várias partes e juntamos com a função paste0(). Fizemos isso para ficar mais fácil de mudar algo depois. Caso quisermos utilizar outro valor em “statusEstacoes” ou em “Origem”, basta mudarmos os objetos criados e o resto do código continua igual! Ao chamar o url_parse no console, verá uma imagem similar ao site quando abrimos o url.

Para puxar agora as informações dessas estações, precisamos entender melhor o arquivo original no formato XML. De maneira resumida, arquivos no formato XML ou HTML possuem estruturas que são definidas entre "< >". Ao mexer no url que nos dá todas as estações, percebe-se que todos os dados de cada estação são precedidos por um elemento chamado "Table" (dentro do "<>"). Porém, queremos os nodes que estão associados a esses "Tables" (tabelas). Para isso, samos a função getNodeSet(). Com os argumentos dessa função sendo primeiro o objeto criado no R depois de ter feito um xmlParse() e o segundo argumento sendo "//Table" (lembrar de colocar essas duas barras)

```{r XML_ANA_info_2, echo=FALSE, fig.align = 'center', out.width = "90%", fig.cap = ""}
knitr::include_graphics("images/XML_ANA_info_2.png")
```

A próxima etapa agora é transformar esse arquivo em algo que estamos mais acostumados a mexer dentro do R. Boas opções são dataframes e listas. Como não aprendemos a mexer muito com listas, vamos transformar nosso objeto em um dataframe. Para isso utilizamos a função xmlToDataFrame().

```{r XML_to_DF_ANA}
nodes_doc <- XML::getNodeSet(url_parse, "//Table")
cadastro_estacoes <- XML::xmlToDataFrame(nodes = nodes_doc)
```

Agora podemos fazer as manipulações que já aprendemos anteriormente (com dataframe ficou fácil!). Por exemplo, se quisermos selecionar apenas as estações de Brasília, escrevemos o código abaixo. O "Municipio-UF" é apenas uma das colunas do dataframe, podemos filtrar com base em qualquer outra também. Vemos então a estrutura desse dataframe criado, usando a função `str()`, e as primeiras 5 linhas delem usando a função `head()`.

```{r Filtrar_cadastro_estacoes_ANA}
estacoes_bsb <- dplyr::filter(cadastro_estacoes, `Municipio-UF` == "BRASÍLIA-DF")
str(estacoes_bsb)
head(estacoes_bsb)
```
 
Lembrando que isso tudo nos dá apenas a lista com informações sobre as estações telemétricas. Para de fato termos acesso aos dados dessas estações, precisamos acessar outro url e fazer mais alguns códigos!

Idealmente, se a gente quiser ficar sempre puxando diferentes informações e não ficar precisando rodar linha por linha de código, podemos juntar tudo isso em uma função. Para a nossa função, deixaremos o processo um pouco melhor. Primeiro definiremos que a função precisa de 3 parâmetros (o status da estação, a origem e qual Unidade Federativa do Brasil queremos). Após puxar os dados em XML e transformar tudo em um dataframe, fazemos aqui algo novo - criamos uma coluna chamada "UF" contendo apenas as últimas duas letras do Município (isos porque no arquivo original, as duas últimas letras são as siglas da UF).

```{r Funcao_puxar_info_ANA}
ANA_info <- function(status_codigo = "",
                     origem_codigo = "",
                     UF_fun = "DF"){

  # Essas etapas foram vistas anteriormente
  url_base <- paste0("http://telemetriaws1.ana.gov.br/ServiceANA.asmx/ListaEstacoesTelemetricas?",
                     "statusEstacoes=", status_codigo,
                     "&origem=", origem_codigo)
  url_parse <- XML::xmlParse(url_base, encoding = "UTF-8")
  nodes_doc <- XML::getNodeSet(url_parse, "//Table")
  cadastro_estacoes <- XML::xmlToDataFrame(nodes = nodes_doc)
  
  # Aqui criamos uma coluna no dataframe apenas com nomes das UFs
  cadastro_estacoes$UF <- substr(cadastro_estacoes$`Municipio-UF`,
                                 nchar(cadastro_estacoes$`Municipio-UF`) - 1,
                                 nchar(cadastro_estacoes$`Municipio-UF`))
                                 
  estacoes_UF <- dplyr::filter(cadastro_estacoes, `UF` == UF_fun)

  return(estacoes_UF)
}
```

Podemos simplesmente testar essa função criada chamando a função e atribuindo para um objeto qualquer (chamamos aqui de "teste") seu resultado. Em seguida falamos para o R printar as colunas desse dataframe.

```{r teste_fun_puxad_info_ANA}
# Testar a função feita!
teste <- ANA_info()
colnames(teste)
```

### Dados Hidrometeorológicos da ANA

Para acessar os dados hidrometeorológicos nesse webservice, temos outro url: <http://telemetriaws1.ana.gov.br/ServiceANA.asmx?op=DadosHidrometeorologicos>. Nele, vemos que são necessárias agora três parâmetros para fazermos uma busca: o “codEstacao” (que a gente pegou na parte anterior!), a “dataInicio” e a “dataFim”. Do mesmo jeito de antes, vamos definir um objeto para cada parâmetro e depois criar um url baseado nesses parâmetros. Em seguida fazemos um xmlParse() e pegamos as informações contidas nos nodes com o getNodeSet(). Por último, transformamos isso em um dataframe. Dessa vez, podemos fazer a função direto ja!

```{r dados_hidro_ANA_1}
dados_ANA <- function(cod_estacao = "",
                      data_inicio = "01/01/2020",
                      data_fim = Sys.Date()){

  # Puxar dados do url e transformar em dataframe
  url_base <- paste0("http://telemetriaws1.ana.gov.br/ServiceANA.asmx/DadosHidrometeorologicos?",
                     "codEstacao=", cod_estacao,
                     "&dataInicio=", data_inicio,
                     "&dataFim=", data_fim)
  url_parse <- XML::xmlParse(url_base, encoding = "UTF-8")
  node_doc <- XML::getNodeSet(url_parse, "//DadosHidrometereologicos")
  dados_estacao <- XML::xmlToDataFrame(nodes = node_doc)
  
  return(dados_estacao)
}
```

A partir da função que criamos anteriormente, para puxar as informações das estações, podemos ver os códigos de todas as estações. Um exemplo é a FAL, da própria UnB. Seu código é 60478482 - podemos usar ele na nossa nova função "dados_ANA". Para ver o que essa função criada retorna, podemos pedir ao R as primeiras 6 linhas desse dataframe.

```{r dados_FAL_1}
dados_FAL <- dados_ANA(cod_estacao = 60478482)
head(dados_FAL)
```

Percebemos aqui um "problema". A data e a hora estão na mesma coluna e idealmente queremos deixar em colunas separadas (uma contendo a data e outra contendo as horas). Então iremos adicionar dentro da nossa função, mais um comando para fazer essa separação. Um jeito simples (mas não o único) de fazer isso é selecionando os primeiros 10 caracteres como sendo os de data e os últimos 8 como sendo de hora - porque a data sempre vai estar no formato "dia/mes/ano" e o horário em "hora:minuto:segundo". Podemos também reorganizar as colunas do jeito que quisermos. Abaixo está essa nova função mais organizada. 

```{r dados_hidro_ANA_2}
dados_ANA <- function(cod_estacao = "",
                      data_inicio = "01/01/2020",
                      data_fim = Sys.Date()){

  # Puxar dados do url e transformar em dataframe
  url_base <- paste0("http://telemetriaws1.ana.gov.br/ServiceANA.asmx/DadosHidrometeorologicos?",
                     "codEstacao=", cod_estacao,
                     "&dataInicio=", data_inicio,
                     "&dataFim=", data_fim)
  url_parse <- XML::xmlParse(url_base, encoding = "UTF-8")
  node_doc <- XML::getNodeSet(url_parse, "//DadosHidrometereologicos")
  dados_estacao <- XML::xmlToDataFrame(nodes = node_doc)
  
  # Separar data e hora
  dados_estacao$Data <- substr(dados_estacao$DataHora, 1, 10)
  dados_estacao$Hora <- substr(dados_estacao$DataHora, 12, 19)

  # Re-organizar a ordem das colunas do dataframe dados_estacao
  dados_estacao <- dados_estacao[,c(1, 6, 7, 3, 4, 5)]
  
  return(dados_estacao)
}
```

Chamamos novamente essa função (agora atualizada) para rodar a estação da FAL. Em seguida printamos no R apenas as primeiras 6 linhas desse dataframe.

```{r dados_FAL_2}
# Rodar a função para a estação da FAL
dados_FAL <- dados_ANA(cod_estacao = 60478482)
head(dados_FAL)
```

Aqui rodamos a função apenas para uma estação. Mas se quisermos rodar para várias estações, basta utilizar um loop (for) ou até mesmo a função lapply do R (mais rápido!).

### Série Histórica

Outro local do HidroWeb da ANA que possui dados hidrológicos relevantes é na seção de série histórica, disponível *online* em: http://telemetriaws1.ana.gov.br/ServiceANA.asmx?op=HidroSerieHistorica. Para puxar esse arquivo dentro do **R** é possível fazer algo similar ao feito acima. Nessa seção, porém, são necessários 5 argumentos:

- **codEstacao** (código da estação);
- **dataInicio** (primeira data em que se quer os dados);
- **dataFim** (última data em que se quer os dados);
- **tipoDados** (podendo ser cotas, 1, chuvas, 2, ou vazões, 3);
- **nivelConsistencia** (podendo ser Bruto, 1, ou consistido, 2).

Primeiro então criamos objetos contendo essas informações necessárias para entrar no *url* da série histórica.

```{r serie_historica_1}
cod_estacao <- 60435000
data_inicio <- "01/01/1800"
data_fim <- Sys.Date()
tipo_dados <- 3
nivel_consist <- 1
```

Em seguida, esses objetos são utilizados para criar um *url* para podermos acessar os dados do HidroWeb. Após é feito o mesmo que a cima em outros portais dentro do portal da ANA, fazendo então um `XML::xmlParse()`, seguido por um `XML::getNodeSet()` e `XML::xmlToDataFrame()`. Assim como anteriormente, faz-se também a separação da coluna de data em duas, uma contendo a data e outra contendo a hora. Na coluna de Data é feita a transformação de *character* para *Date* de modo que possamos fazer algumas operações com ela depois.

obs: Por algum motivo o hidroweb não está filtrando os dados pela consistencia, sendo necessária essa etapa abaixo (um filtro).

```{r serie_historica_2}
# Puxar dados do url e transformar em dataframe
url_base <-
  paste0("http://telemetriaws1.ana.gov.br/ServiceANA.asmx/",
         "HidroSerieHistorica?",
         "codEstacao=", cod_estacao,
         "&dataInicio=", data_inicio,
         "&dataFim=", data_fim,
         "&tipoDados=", tipo_dados,
         "&nivelConsistencia=", nivel_consist)
         
url_parse <- XML::xmlParse(url_base, encoding = "UTF-8")
node_doc <- XML::getNodeSet(url_parse, "//SerieHistorica")
dados_estacao <- XML::xmlToDataFrame(nodes = node_doc)

# Separar data e hora
dados_estacao$Data <- as.Date(substr(dados_estacao$DataHora, 1, 10))
dados_estacao$Hora <- substr(dados_estacao$DataHora, 12, 19)
```

É interessante lembrar um pouco como funciona esse formato de datas aqui. As datas podem vir de inúmeras formas diferentes de algum banco de dados. Elas podem vir com "dia - mês - ano", com o ano podendo ser escrito com todos os dígitos (2022) ou apenas os últimos dois (22). Outra coisa que pode ser alterada é a ordem ("dia - mês - ano" ou "ano - mês - dia" ou qualquer variação desses três. Ainda podemos encontrar em bases de dados o mês escrito por extenso ou abreviado como "01/Jan/1990". Isso sem contar com o separador dessas datass ("/", "-", um espaço em branco...). Podemos definir isso dentro da função `as.Date()`, utilizando como argumento a seguinte convenção:

- **%Y** para anos com quatro dígitos;
- **%y** para anos com dois dígitos;
- **%d** para os dias (dígitos de 1 a 31);
- **%m** para os meses (dígitos de 1 a 12);
- **%b** para meses no formato abreviado em inglês (*Jan*, *Feb*, ...);
- **%B** para meses no formato por extenso em inglês (*January*, *February*, ...).

Essa função do **R** possui um argumento que irá ficar tentando diversos formatos diferentes e tomará como verdade o primeiro que não retornar valores NA - porém, para formatos específicos (e se já sabemos qual é), pode ser melhor já deixar isso explícito em seu código.

```{r serie_historica_3}
as.Date("2021-11-01", format = "%Y-%m-%d")
as.Date("01/Jan/70", format = "%d/%b/%y")
```

Nesse arquivo temos a necessidade de uma nova etapa. Ao olhar um pouco como os dados estão oganizados, percebemos que existem 78 colunas. Ao invés dos dados de vazão estarem todos em uma mesma coluna, eles estão espaçados por coluna, contendo 1 mês completo para cada linha do dataframe. Isso é um pouco problemático, pois não podemos simplesmente puxar todas as colunas visto que cada mês vai ter datas diferentes (fevereiro podendo até mudar dependendo do ano bisexto). Para resolver isso, primeiro criamos um vetor/objeto contendo **todas** as datas desde o primeiro mês em questão, até o útimo dia do último mês.

```{r serie_historica_4}
datas_dia <- seq.Date(from = min(dados_estacao$Data),
                      to = max(dados_estacao$Data) %m+% months(1) - 1,
                      by = "day")
```

É extremamente interessante notar duas coisas aqui. Primeiro, sempre temos diferentes formas de fazer um código, isso vai variar muito com a lógica de cada programador. Acima utilizamos uma função feita do pacote **lubridate** para somar um mês a uma certa data. Porém, podemos fazer o mesmo sem utilizar pacotes adicionais. Apesar deles ajudarem, podem tornar a manutenção do seu código algo essencial - as vezes o pacote pode alterar funções com atualizações ou até mesmo tornarem algumas obsoletas! Abaixo então fazemos a mesma sequência de outra forma, e ao final comparamos se ambas são idênticas.

```{r serie_historica_5}
datas_i <- min(dados_estacao$Data)
datas_f <- seq.Date(max(dados_estacao$Data), by = "month", length.out = 2)[2] - 1

datas_dia_v2 <- seq.Date(from = datas_i,
                         to = datas_f,
                         by = "day")
                         
identical(datas_dia, datas_dia_V2)
```

Em seguida fazemos um dataframe vazio, contendo 3 colunas. A primeira possui o código da estação sendo avaliado (como repete para todas as linhas, podemos pegar apenas o primeiro valor). A segunda as datas, no formato *character* (útil para manipulação de texto), e a última sendo a coluna com os dados de vazão que está, por hora, vazio.

```{r serie_historica_6}
tabela_final <- data.frame(Cod_estacao = dados_estacao$EstacaoCodigo[1],
                           Data = as.character(datas_dia),
                           Vazao = as.numeric(NA))
```

Agora vamos preencher essa tabela com os dados de vazão do arquivo acessado. Uma maneira de fazer isso é fazendo um *loop* para cada linha dessa tabela. Para cada linha, acessamos o dia em questão (o dia é sempre os últimos 2 caracteres da coluna data). Em seguida obtemos o mês e ano dessa data (os primeiros oito caracteres da coluna de data) e adicionamos o dia "-01" a eles (isso para sabermos em qual linha do arquivo da ANA está o dado) - para isso criamos o objeto *linha_dado*. Por último rodamos um `ifelse()` do tipo: se eu não tiver essa *linha_dado*, ou seja, se não houver medição desse mês na ANA, eu coloco um `NA` (*Not Available*) na tabela final, caso o contrário é pego o valor na linha definida e na coluna do dia + 15 (é somado 15 porque as colunas de dia começam a partir da coluna 16).

```{r serie_historica_7}
for(i in 1:nrow(tabela_final)){
  # Dia em análise
  dia <- as.numeric(substr(tabela_final$Data[i], 9, 10))
    
  # Mês e ano em análise
  mes_ano <- as.Date(paste0(substr(tabela_final$Data[i], 1, 8), "01"))
  
  # Olhar a linha do mes e ano e escolher a coluna pelo dia + 15
  linha_dado <- which(dados_estacao$Data == mes_ano)
  
  # Se não tiver o mês nos dados da estação, colocar valor NA
  ifelse(length(linha_dado) == 0,
         tabela_final$Vazao[i] <- NA,
         tabela_final$Vazao[i] <-
           as.numeric(dados_estacao[linha_dado, (dia + 15)]))
    
}
```

Novamente, poderíamos fazer esse código acima utilizando pacotes para "facilitar a nossa vida" (o *lubridate* para mexer com datas). Por exemplo, poderíamos usar a função `day()` para puxar o dia de cada linha (usando a coluna no formato de *Date*) ao invés de fazer uma manipulação de texto. Aqui não vemos se são idênticos porque não são (a função `day()` retorna números inteiros), portanto utilizamos a função `all.equal()` que avalia, até certo ponto, se são praticamente iguais.

```{r serie_historica_8}
exemplo_dia <- as.numeric(substr(tabela_final$Data, 9, 10))
exemplo_dia_v2 <- day(as.Date(tabela_final$Data))
 
all.equal(exemplo_dia, exemplo_dia_v2)
```

Pronto, agora podemos ver, por exemplo, as primeiras 5 medições que não são `NA`

```{r serie_historica_9}
head(tabela_final[!is.na(tabela_final$Vazao),])
```

Assim como feito nas outras etapas, podemos aqui fazer uma função para automatizar tudo que foi feito em várias etapas para deixar o processo mais automatizado e mais fácil quando quiser rodar o mesmo processo para outras estações.

```{r serie_historica_10_funcao}
dados_serie_ANA <- function(cod_estacao = NA,
                            data_inicio = "01/01/1800",
                            data_fim = Sys.Date(),
                            tipo_dados = 3,
                            nivel_consist = 1){
  
  # Puxar dados do url e transformar em dataframe
  url_base <-
    paste0("http://telemetriaws1.ana.gov.br/ServiceANA.asmx/",
           "HidroSerieHistorica?",
           "codEstacao=", cod_estacao,
           "&dataInicio=", data_inicio,
           "&dataFim=", data_fim,
           "&tipoDados=", tipo_dados,
           "&nivelConsistencia=", nivel_consist)
  
  url_parse <- XML::xmlParse(url_base, encoding = "UTF-8")
  node_doc <- XML::getNodeSet(url_parse, "//SerieHistorica")
  dados_estacao <- XML::xmlToDataFrame(nodes = node_doc)
  
  # Por algum motivo o hidroweb não está filtrando os dados pela consistencia
  dados_estacao <- filter(dados_estacao, NivelConsistencia == nivel_consist)
  
  # Separar data e hora
  dados_estacao$Data <- as.Date(substr(dados_estacao$DataHora, 1, 10))
  dados_estacao$Hora <- substr(dados_estacao$DataHora, 12, 19)
  
  # Fazer um dataframe só com datas e valores de vazão
  datas_dia <- seq.Date(from = min(dados_estacao$Data),
                        to = max(dados_estacao$Data) %m+% months(1) - 1,
                        by = "day")
  tabela_final <- data.frame(Cod_estacao = dados_estacao$EstacaoCodigo[1],
                             Data = as.character(datas_dia),
                             Vazao = as.numeric(NA))
  
  
  for(i in 1:nrow(tabela_final)){
    dia <- as.numeric(substr(tabela_final$Data[i], 9, 10))
    mes_ano <- as.Date(paste0(substr(tabela_final$Data[i], 1, 8), "01"))
    linha_dado <- which(dados_estacao$Data == mes_ano)
    ifelse(length(linha_dado) == 0,
           tabela_final$Vazao[i] <- NA,
           tabela_final$Vazao[i] <-
             as.numeric(dados_estacao[linha_dado, (dia + 15)])) 
  } # fim do loop
  return(tabela_final)
}
```

Para testar essa função basta utilizar a linha abaixo.

```{r serie_historica_11_fun}
dados_60435000 <- dados_serie_ANA(cod_estacao = 60435000)
dados_60435000[10:15,]
```

## Salvar arquivos

### Salvar um arquivo único

Uma etapa tão importante quanto baixar os próprios dados que se precisa é conseguir salvar eles antes ou depois de alguma manipulação feita. Isso pode ser feito pelo  **R** utilizando as funções `write.table()`, `write.csv()` ou variações delas - da mesma forma que haviam variações em `read.table()` `read.csv()`.

Uma boa prática é deixar todos os argumentos mais importantes explícitos, para que não tenha dúvidas de qua função usar ou como se irá salvar. Assim deixa-se explícito abaixo o separador (*tab*), os decimais ("."), que não irá salvar o nome das linhas (elas não tem nome) e a codificação do arquivo (acentos e etc.).

```{r salvar_arq_1, eval = FALSE}
write.table(x = dados_60435000,
            file = "dados_60435000.txt",
            sep = "\t",
            dec = ".",
            row.names = FALSE,
            fileEncoding = "UTF-8")
```

### Salvar em um loop

A vantagem de utilizar funções e automatizações é fazer tudo que foi feito acima para *n* estações, não apenas uma! Selecionamos já 4 estações de uma mesma bacia para fazermos análises mais a frente. Os códigos delas são:

- 60435000 (feita);
- 60436000;
- 60436190;
- 60443000 (última estação).

Para fazer isso, podemos rodar a nossa funão criada, `dados_serie_ANA()`, para cada uma dessas estações. Depois de rodar a função, podemos rodar também o código para salvar elas! Note que o **i** interno ao `for()` não precisa ser uma sequência, ele apenas informa quais os valores que **i** vai tomar a cada iteração. Na hora de salvar usamos a função `paste0()` pois o nome vai variar com cada iteração.

```{r salvar_arq_2, eval = FALSE}
for(i in c(60435000, 60436000, 60436190, 60443000)){
  dados_proxy <- dados_serie_ANA(i)
  
  write.table(x = dados_proxy,
              file = paste0(i, ".txt"),
              sep = "\t",
              dec = ".",
              row.names = FALSE,
              fileEncoding = "UTF-8")
}
```

Agora temos 4 arquivos, um para cada estação que definimos, salvos em formato *.txt* do jeito que queremos - o que tornará a próxima etapa de manipulação muito mais fácil. Ao invés de termos um arquivo para cada estação com 78 colunas e as vazões podendo estar em diferentes linhas e colunas temos uma tabela bem simples, com apenas 3 colunas. Uma contendo o código da estação, outra a data e a última o valor de vazão observado. Se quisermos fazer um *loop* para salvarmos os 4 arquivos em um mesmo data.frame também podemos o fazer. Segue abaixo esse último exemplo.

```{r salvar_arq_3, eval = FALSE}
estacoes <- c(60435000, 60436000, 60436190, 60443000)

for(i in 1:4){
  # Qual estação estamos avaliando nesse loop específico
  estacao_proxy <- estacoes[i]
  
  # Rodar a função criada
  dados_proxy <- dados_serie_ANA(estacao_proxy)
  
  # Juntar as estações em uma só
  if(i == 1) todas_estacoes <- dados_proxy
  if(i != 1) todas_estacoes <- rbind(todas_estacoes, dados_proxy)
}

write.table(x = todas_estacoes,
            file = "todas_estacoes.txt",
            sep = "\t",
            dec = ".",
            row.names = FALSE,
            fileEncoding = "UTF-8")
```
