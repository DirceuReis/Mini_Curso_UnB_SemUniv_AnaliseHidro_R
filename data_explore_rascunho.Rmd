---
title: "Análise exploratória dos dados: Parte 2"
description: Rascunho de novas análises com **R**
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::knit_hooks$set(inline = function(x) {
#  x <- sprintf("%1.2f", x)
#  paste(x, collapse = ", ")
#})
library(tidyverse)
library(lubridate)
```

## Apresentação

Esta página pode ser vista como um rascunho de uma segunda aula em **Análise Exploratória de Dados**, o que significa dizer que ainda está em construção.

A ideia é iniciar com a leitura de dados diários de vazão de uma dada estação, e a partir daí, realizar uma séries de atividades que se constitui basicamente da construção de gráficos que permitam caracterizar, de uma forma geral, o comportamentos das vazões no local.

Segue abaixo, uma lista das análises que se pretende realizar nesta aula:

- Construção de curva de permanência a nível diário em três estágios acumulativos:
  - com todos os anos do histórico de uma só vez
  - uma curva para cada ano
  - identificação da curva de permanência dos anos mais úmido e mais seco
- Sazonalidade das máximas anuais (esécie de rosas dos ventos para vazões)
- Construção das mínimas para um dado número de dias consecutivos

## Leitura dos dados diários

Iniciamos esta aula fazendo a leitura do arquivo `txt` que contém os dados de vazão média diária obtidos anteriormente.   

```{r leitura_txt}
## Leitura do arquivo de vazões médias diárias
Qd <- read.table(file = "dados/60435000.txt",
                             sep = "\t",
                             dec = ".",
                             header = T,
                             fileEncoding = "UTF-8",
                             colClasses = c("factor", "Date", "numeric"))
head(Qd,10)
```


## Curva de permanência

A curva de permanência de vazões relaciona os valores de vazão registrados na estação com as respectivas probabilidade de serem excedidos. Costuma-se representar os valores de vazão no eixo-y e a probabilide de excedência no eixo-x. Costuma-se interpretar a probabilidade de excedência como o percentual do tempo em que se observa valores de vazão maior ou iguais ao valor em questão.

Para construrios uma curva de permanência com os dados apresentados acima, criaremos uma nova coluna no nosso `dataframe`, denominado `Qd`, com os valores do ano corrspondente, informação disponível na coluna de `Data`. Isso nos ajudará nas etapas posteriores de cálculo. 

Além disso, removeremos os anos em que haja falha nos dados de vazão, evitando distorções no cálculo dos percentis de vazão, necessários para a criação da curva de permanência. Essas duas etapas são realizadas no código abaixo, 

```{R preparo_data}
## Criação de coluna com os anos
Qd <- Qd %>% 
  mutate(Ano = year(Data))

## Remoção de anos que contenham dias com falha
Anos_falha <- unique(Qd$Ano[is.na(Qd$Vazao)])
Anos_falha
Qd <- Qd %>% 
          filter(!(Ano %in% Anos_falha))
tibble(Qd)
```

Podemos notar que os anos `r Anos_falha` continham falhas e foram removidos de nossa análise. A série restante contém um total de `r nrow(Qd)` observações, relativas a `r length(unique(Qd$Ano))` anos de dados sem falhas, com início em `r Qd$Ano[1]` e fim em `r Qd$Ano[nrow(Qd)]`. 

Constuiremos primeiro a curva de permanência tradicional, aquela em que as obervações de todos os anos do histórico são empregadas no cálculo da probabilidade de excedência. Aqui, utilizaremos a chamada posição de plotagem de Weibull, conforme equação abaixo,

$$
P(Q>q_{(i)})=\frac{i}{n+1}
$$

em que $q_{(i)}$ é a i-ésima maior vazão observada, $i$ é o posto (*ranking*) da observação, e $n$ é o número de observações. Só para deixar claro, a probabilidade da vazão média diária ultrapassar a maior vazão média diária já registrada vale

$$
P(Q>q_{(1)}) = \frac{1}{n+1}
$$

Utilizamos o código abaixo, escrito em `R-base`, para realizar esse cálculo. AO final, apresentamos as primeiras 10 linhas do `dataframe` denominado `Qperm_all`, com os valores da probabilidade de excedência localizados na última coluna. 

```{r Perm_all}
# Permanência calculada com todos os anos juntos 
# Uso do R-base apenas
Qperm_all <- Qd[order(Qd$Vazao, decreasing = TRUE), ]
Qperm_all$index <- 1:nrow(Qperm_all)
Qperm_all$weibull <- Qperm_all$index/(nrow(Qperm_all)+1) 
tibble(Qperm_all)
```

Note que as vazões estão ordenadas de forma decrescentte, com o maior valor do histórico tendo ocorrido em `r Qperm_all$Data[1]`. 

Poderíamos ter obtido o mesmo resultado utilizando o pacote `tidyverse`, como pode ser observado abaixo. É sempre bom saber realizar algo de manieras diferentes. Utilize a que você achar mais fácil.

```{r perm-all-tidy}
Qperm_allt <- Qd %>% 
  arrange(desc(Vazao)) %>%
  mutate(index = rank(-Vazao)) %>%
  mutate(weibull = index/(n()+1))
tibble(Qperm_allt)
```

Agora já temos os elementos necessários para realizar a plotagem da curva de permanência, quais sejam: a vazão média diária (eixo-y), armazenada na coluna `Vazao` de nosso `dataframe`, e a probabilidade de excedênia (eixo-x), armazeada na coluna `weibull`.

O código abaixo faz a plotagem utilizando o pacote `ggplot2`. Plotamos a vazão na escala logarítmica para facilitar a visualização. 

```{r plot-perm-all, warning=FALSE,fig.width = 8, fig.height = 6}
ggplot() +
  geom_line(data = Qperm_all,aes(weibull,Vazao),colour = 'black', size = 1) +
  scale_y_continuous(name = 'Vazão média diária (m3/s)',
                     trans = 'log10', 
                     breaks = c(0.01, 0.1, 1, 10, 100, 1000, 10000),
                     limits = c(0.05, 20),
                     labels = c(0.01, 0.1, 1, 10, 100, 1000, '10,000')) +
    scale_x_continuous(name = 'Percentual do tempo acima',
                     limits = c(0.01,0.99),
                     breaks = c(0.01, 0.05,0.1,0.25,0.5,0.75, 0.9,0.95, 0.99),
                     labels = c('1%','5%', '10%', '25%', '50%', '75%', '90%','95%', '99%'))
```

O próximo passo é determinar as curvas de permanência para cada uma dos anos do histórico, e plotá-las junto com a curva acima. Isso nos dará uma ideia do grau de variabilidade da curva de permanência de ano para ano. 

Aqui, nos restringiremos a usar o pacote `tidyverse` para rearrumar o `dataframe` e realizar as operações necessárias. Como faremos uma curva de permanência para cada ano do histórico, precisaremos calcular as probabilidades de excedência de forma separada para cada ano. Faremos isso utilizando a função `group_by`, como apresentado no código abaixo,

```{r}
# Permanência calculada para cada ano
# Uso do tidyverse e pipe
Qperm_ano <- Qd %>% 
  arrange(Ano, desc(Vazao)) %>%
  group_by(Ano) %>%
  mutate(index = rank(-Vazao)) %>%
  mutate(weibull = index/(n()+1))
tibble(Qperm_ano)
```

Só nos resta agora fazer a plotagem. Como incluiremos 40 novas curvas, é importante que utilizemos uma linha bem fina e uma cor bastante suave. Utilizaremos a cor `gryy70` com tamanho `0.2`. Você pode experimentar as diferentes possibilidades que o `ggplot2` oferece.

O código para a plotagem segue abaixo,

```{r plot-perm-all-anos, warning=FALSE,fig.width = 8, fig.height = 6}
ggplot() +
  geom_line(data = Qperm_ano,aes(x = weibull, y = Vazao,group = Ano),
              colour = 'grey70', size = 0.2) +
  geom_line(data = Qperm_all,aes(weibull,Vazao),colour = 'black', size = 1) +
    scale_y_continuous(name = 'Vazão média diária (m3/s)',
                     trans = 'log10', 
                     breaks = c(0.01, 0.1, 1, 10, 100, 1000, 10000),
                     limits = c(0.05, 20),
                     labels = c(0.01, 0.1, 1, 10, 100, 1000, '10,000')) +
    scale_x_continuous(name = 'Percentual do tempo acima',
                     limits = c(0.01,0.99),
                     breaks = c(0.01, 0.05,0.1,0.25,0.5,0.75, 0.9,0.95, 0.99),
                     labels = c('1%','5%', '10%', '25%', '50%', '75%', '90%','95%', '99%'))
```

Podemos perceber uma faixa de variação relativamente grande de ano para ano para os diferentes valores de percentis. 

Para faciliatr a visualização, faremos duas modificações na Figura acima. Primeiro, vamos alterar a linha de grade, tornando-a mais refinada. Depois, iremos fazer uma transformação no eixo-x para deixar mais claro o comportamento dessas curvas nas regiões extremas da probabilidade de excedência.

Para a primeira parte, utilizaremos a função abaixo, que constrói um novo conjunto de linhas de grade na escala logarítmica, código este que foi retirado do link abaixo. Para a segunda parte, empregaremos uma transformação do tipo `probit` aos valores de probabilidade, transformando essas porbabilidades em quantis da distribuição normal-padrão.

```{r}
# Function to plot minor breaks at a log scale
# https://stackoverflow.com/questions/30179442/plotting-minor-breaks-on-a-log-scale-with-ggplot
log10_minor_break = function (...){
  function(x) {
    minx         = floor(min(log10(x), na.rm=T))-1;
    maxx         = ceiling(max(log10(x), na.rm=T))+1;
    n_major      = maxx-minx+1;
    major_breaks = seq(minx, maxx, by=1)
    minor_breaks = 
      rep(log10(seq(1, 9, by=1)), times = n_major)+
      rep(major_breaks, each = 9)
    return(10^(minor_breaks))
  }
}

log10_major_break = function (...){
  function(x) {
    minx         = floor(min(log10(x), na.rm=T))-1;
    maxx         = ceiling(max(log10(x), na.rm=T))+1;
    n_major      = maxx-minx+1;
    major_breaks = seq(minx, maxx, by=1)
    return(10^(major_breaks))
  }
}

```

O código para a nova Figura segue na sequência,

```{r plot-perm-all-anos-v2, warning=FALSE,fig.width = 8, fig.height = 6}
ggplot() +
  geom_line(data = Qperm_ano,aes(x = weibull, y = Vazao,group = Ano),
              colour = 'grey70', size = 0.2) +
  geom_line(data = Qperm_all,aes(weibull,Vazao),colour = 'black', size = 1) +
    scale_y_continuous(name = 'Vazão média diária (m3/s)',
                     trans = 'log10', 
                     breaks = c(0.01, 0.1, 1, 10, 100, 1000, 10000),
                     minor_breaks = log10_minor_break(),
                     limits = c(0.05, 20),
                     labels = c(0.01, 0.1, 1, 10, 100, 1000, '10,000')) +
    scale_x_continuous(name = 'Percentual do tempo acima',
                     trans = 'probit', 
                     limits = c(0.01,0.99),
                     breaks = c(0.01, 0.05,0.1,0.25,0.5,0.75, 0.9,0.95, 0.99),
                     labels = c('1%','5%', '10%', '25%', '50%', '75%', '90%','95%', '99%'))
```
Veja que as mudanças implementadas permitiram visualizar melhor os resultados, principalmente para os quantis acima de 90%. 

Dá para notar, por exemplo, que a $Q_{0.95}$ vale 0.38 m$^3$/s quando se emprega todo o conjunto de anos do histórico, muito embora, numa análise a nível anual,  seu valor pode variar entre entre 1.48 m$^3$/s e 0.07 m$^3$/s.

Para finalizar este esta atividade em relação à curva de permanência, e para chamar a atenção para essa variabilidade de ano para ano, vamos identificar o ano mais seco e o ano mais úmido, e diferenciá-los na Figura acima. 

Para isso, precisamos identificar quem são esses anos. Vamos utilizar como métrica para a definição do ano mais e do ano mais seco, a vazão média anual.

O código abaixo mostra com essa identificação pode ser feita,

```{R anos-seco-umido}
## Determina o ano mais úmido e o ano mais seco
Qanual <- Qd %>%
  group_by(Ano) %>%
  summarise(Qano = mean(Vazao))
ano_seco <- as.numeric(Qanual[which.min(Qanual$Qano),1])
ano_seco
ano_umido <- as.numeric(Qanual[which.max(Qanual$Qano),1])
ano_umido
```
Para tornar as curvas de permanência de 1983 e 2017 mais proeminentes na Figura acima, basta colorí-las. 

Para isso, vamos construir um novo `dataframe` apenas ocm esses anos,

```{r}
anos_extremos <- Qd %>% 
  filter(Ano %in% c(ano_seco, ano_umido)) %>% 
  arrange(Ano, desc(Vazao)) %>%
  group_by(Ano) %>% 
  mutate(index = rank(-Vazao)) %>%
  mutate(weibull = index/(n()+1))
tibble(anos_extremos)
```

Fazemos isso no código abaixo, incluindo uma legenda para identificar quem é quem.

```{r, warning = FALSE,fig.width = 8, fig.height = 6}
# Plotagem
  ggplot() +
    geom_line(data = Qperm_ano,aes(x = weibull, y = Vazao,group = Ano),
              colour = 'grey70', size = 0.2) +   
    geom_line(data = Qperm_all,aes(weibull,Vazao),colour = 'black', size = 1) +
    geom_line(data = anos_extremos, aes(x = weibull, y = Vazao, colour = factor(Ano)), size = 1) +
    scale_colour_discrete(name = NULL) +
    theme(legend.position = 'bottom',text = element_text(size = 10)) +
    scale_y_continuous(name = 'Vazão média diária (m3/s)',
                     trans = 'log10', 
                     breaks = c(0.01, 0.1, 1, 10, 100, 1000, 10000),
                     minor_breaks = log10_minor_break(),
                     limits = c(0.05, 20),
                     labels = c(0.01, 0.1, 1, 10, 100, 1000, '10,000')) +
    scale_x_continuous(name = 'Percentual do tempo acima',
                     trans = 'probit', 
                     limits = c(0.01,0.99),
                     breaks = c(0.01, 0.05,0.1,0.25,0.5,0.75, 0.9,0.95, 0.99),
                     labels = c('1%','5%', '10%', '25%', '50%', '75%', '90%','95%', '99%'))

```

## Sazonalidade das vazões máximas anuais

Quando o interesse se dá na modelagem das vazões máximas de um dada estação fluviométrica, é importante compreender quando, ao longo do ano, esses eventos mais extremos ocorrem, de forma a analisar os possíveis mecanismos geradores dessas grandes cheias. 

Na modelagem estatística de eventos de cheia, costuma-se assumir, a priori, que a série de máximos é homogênea, o que justifica o uso de apenas uma distribuição teórica de probabilidades. 

Entretanto, isso nem sempre é verdade, pois é possível que haja diferentes mecanismos físicos geradores das vazões mais altas. Esses mecanismos podem ocorrer em diferentes épocas do ano, de forma que num dado ano, digamos, a maior cheia possa ter ocorrido devido ao mecanismo **A**, enquanto que no ano seguinte, tenha sido o resultado do mecanismo gerador **B**. Em casos como esse, o mais indicado é modelar as vazões máximas como uma combinação de duas distribuições distintas, uma para cada mecanismo gerador.

Visualizar quando as grandes cheias usualmente ocorrem ao longo do ano é um primeiro passo nesse tipo de análise, e isso é exatamente o que faremos aqui.

Iniciamos esta atividade criando um novo `dataframe`, baseado no `dataframe` de vazões média diárias sem falhas, `Qd` (ver **Curva de Permanência**).

Este novo `dataframe` irá conter quatro colunas:

- col1: código da estação
- col2: ano hidrológico
- col3: vazão máxima daquele ano hidrológico
- col4: data da ocorrênca da vazão máxima

Para isso, utilizaremos a função `fun_max_ano`, apresentada abaixo,

```{r}
# Contrução da série de máximos anuais a partir de um ano hidrológico ####
fun_max_ano <- function(tabela = NA,
                        comeco_ano_hidro = 8){
  
  # Transformar a coluna Data em "Dates" (caso esteja em character)
  tabela$Data <- as.Date(tabela$Data)
  
  # Definir se o mês em questão entra no ano atual ou no próximo ano
  desloc_ano <- ifelse(month(tabela$Data) < comeco_ano_hidro, 0, 1)
  
  # Ano Hidro
  tabela$ano_hidro <- year(tabela$Data) + desloc_ano
  
  # Fazer uma tabela final apenas com os máximos anuais e a respectiva data de ocorrência
  max_anuais <-
    tabela %>%
    group_by(Cod_estacao, ano_hidro) %>%
    summarise(maxima = max(Vazao),
              data_maxima = Data[which.max(Vazao)])
}

```

Veja que a função `fun_max_ano` assume que o ano hidrológico começa no mês de agosto, o que parece razoável para a estação que estamos utilizando. Se você achar que o ano hidrológico deve começar em outro mês, defina o mês quando chamar a função.

Chamamos a referida função e criamos o `dataframe` denominado `Q_max`, cujas primiras linhas podem ser observadas na sequência.

```{r , message=FALSE}
Q_max <- fun_max_ano(Qd)
tibble(Q_max)
```
Agora que já temos a data completa da ocorrência de cada uma das vazões máximas anuais, precisamos mapeá-las para coordenada polar de forma que seja possível construir uma espécie de rosa dos ventos, mas para as vazões máximas anuais.

A lógica dessa rosa das vazões é que cada ocorrência seja representada por duas variáveis: a magnitude da vazão, representada pelo tamanho do segmento, e a data de ocorrência dentro do ano, representada pela direção do segmento. Aqui, representaremos uma cheia no dia 01 de janeiro com um segmento na direção Note-Sul apontando para cima. Em outras palavras, a duração de cada ano do histórico será representada por uma volta inteira no círculo, enquanto a ocorrência de uma cheia numa data específica será mapeada para um ângulo em radianos.

Para realizar tal mapeamento, faremos uso da função `Date.to.Angle`, apresentada abaixo, gentilmente compartilhada por Tony Ladson em sua conta de GitHub, cujo endereço aparece no início da função.

```{r}
# Função compartihada por Tony Ladson
# https://gist.github.com/TonyLadson/843410a1f9e1f1bbf1f48eeeee79a007
Date_to_Angle <- function(my.date){
  
  start.year <- floor_date(my.date, 'year')
  end.year <- ceiling_date(my.date, 'year')
  length.year <- as.numeric(difftime(end.year, start.year, units = 'sec'))
  time.since.year.start <- as.numeric(difftime(my.date, start.year, units = 'sec'))
  
  2 * pi * time.since.year.start/length.year # date as angle
  
}
```

A função `Date.to.Angle` lê as datas de ocorrência das máximas anuais, e para cada um dos anos, determina o tempo decorrido, em segundos, guardando a resposta na variável `time.since.year.start`. Isso permite lidar de forma adequada com os anos bissextos que por ventura apareçam. 

Na sequência, a função mapeia cada uma das vazões máximas para um ângulo em radianos, assumindo que $2\pi$ radianos tenha exatamente a extensão do ano em segundos.

Com essa função em mãos, podemos criar uma nova coluna do `dataframe` `Q_max` com os ângulos em radianos, e isso é feito no código abaixo, que determina também, nas duas primeiras linhas, quais seriam os valores, em radianos, das datas de início de cada mês do ano, informação necessária para construir a nossa rosa das vazões. 

```{r map-data-radiano}
# gera sequência e calcula ângulo para informações mês a mês
month.start <- yday(seq(as.Date('2010-01-01'),as.Date('2010-12-31'), by='1 months'))
month.start.radians <- 2*pi*month.start/365.25 

# Gera ângulo para cada vazão máxima anual do histórico
Q_max <- Q_max %>% 
  mutate(rad = Date_to_Angle(data_maxima))

```

Para realizar a plotagem, vamos mais uma vez usufruir da generosidade de [Tony Ladson](https://gist.github.com/TonyLadson/843410a1f9e1f1bbf1f48eeeee79a007), que nos fornece o script para a plotagem. Fizemos pequenas adaptações no script original, mas em essência, o script é o mesmo.

```{r, fig.width = 8, fig.height = 6}
ggplot(Q_max,aes(x=rad, y=maxima)) + 
  coord_polar('x', start = 0, direction = 1) + 
  geom_segment(aes(y = 0, xend = rad, yend = maxima)) +
  scale_x_continuous(name = 'Ocorrência das máximas anuais', breaks = month.start.radians, labels = month.name, limits = c(0, 2*pi)) +
  scale_y_continuous(name = bquote('Máximas anuais (m' ^3 *'s' ^-1 *')')) +
  theme_bw() +
  theme(
    panel.background = element_rect(fill="grey99"),
    axis.title.x = element_text(colour="grey20", size=12, margin=margin(20,0,0,0)),
    axis.text.x = element_text(colour="grey20",size=8),
    axis.title.y = element_text(colour="grey20",size=12, margin = margin(0,20,0,0)),
    axis.text.y = element_text(colour="grey20",size=8),
    legend.title = element_text(colour="grey20",size=12),
    plot.margin = unit(c(0.5, 0.5, 1, 0.5), "cm")) # top, right, bottom, left

```

Embora haja espaço para melhorias nessa plotagem, podemos ver claramente que as grandes cheias nesta estação fluviométrica ocorrem entre os meses de dezembro e março, com honrosas exceções em outubro e abril, mas sempre com magnitudes menores. 

## Análise de veranicos de chuva

### Baixar dados de chuva

### Identificar veranicos

### Plotagem de período de veranicos

### Frequência de veranicos de uma dada extensão

## Análise de seca

### Baixar dados de vazão

Iniciamos com a leitura dos dados de vazão. Vamos mais uma vez utilizar os dados da estação fluviométrica **60435000**, que já foram gravados num arquivo do tipo `txt`. 

Apesar de já termos utilizado esses dados nas atividades anteriores, vamos lê-los de novo, pois nós havíamos anteriormente elimanados os anos que continham falhas, o que não é exatamente o que queremos aqui, pelo menos nessa primeira atividade. 

O código abaixo apresenta a maneira como lemos um arquivo `txt` utilizando a função `read.table`.

```{r leitura_txt2}
## Leitura do arquivo de vazões médias diárias
Qd <- read.table(file = "dados/60435000.txt",
                             sep = "\t",
                             dec = ".",
                             header = T,
                             fileEncoding = "UTF-8",
                             colClasses = c("factor", "Date", "numeric"))
head(Qd,10)
```

Como podemos ver, o `dataframe` denominado `Qd` contém três colunas, o código da estação, as datas, e os valores diários de vazão. Nós forçamos que o código da estação seja um `factor` e que as datas sejam da classe `date`.

### Identificar status da vazão (seco ou úmido)

O primeiro passo nessa análise é identificar os períodos em que as vazões diárias estão acima ou abaixo de um valor-limite pré-especificado de vazão.

Essa análise é bastante importante para estudos relacionados a secas e avaliação de impactos causados pelas secas. Dias consecutivos com vazões diárias inferiores ao valor-limite formam os chamdos períodos **secos**, geralmente chamados na literatura inglesa de *dry spells*.

Estimar a frequência de períodos **secos** (*dry spells*) com diferentes comprimentos, assim como descrever o padrão estatístico dos chamados **volumes de defcit**, são procedimentos importantes para entender a extensão de problemas relacionados `a seca numa dada região, desde que o valor-limite de vazão escolhido para realizar a análise tenha alguma relação com a seca local. 

De todo modo, essas grandezas são muitas vezes empregadas para caracterizar o comportamento hidrológica da região, principalmente a propensão a longos períodos com vazões baixas, o que pode representar problemas de escassez hídrica.

A escolha desse valor-limite varia de estudo para estudo. É normal escolher um quantil específico da série de vazões, como a mediana, embora a média também possa ser empregada. Em estudos mais específicos, é comum utilizar a demanda estimada de água para asbastecimento de uma cidade, por exemplo, como o valor-limite de vazão.

O **volume de defcit**, mencionado anteriormente, é simplesmente o volume total acumulado ao longo do período seco, calculado como a diferença entre o volume associado à vazão-limite e o volume que de fato escoou no rio. Essa variável expressa a diferença entre o que se deseja em termos de volume num determinado período e o volume que rio de fato forneceu nesse mesmo período, daí a expressão **volume de defcit**.

Mas o primeiro passo nessa análise é identificar o *status* da vazão do rio, em cada dia, ao longo do histórico. Se a vazão do rio for menor do que a vazão-limite pré-estabelecida, diz-se que o *status* desse dia é seco, caso contrário identificamos esse dia como úmido.

Isso é relativamente fácil de fazer utilizando a linguagem **R**, como podemos ver abaixo. Para fins de ilustração, estamos utilizando o valor de 1 m$^3$/s como valor-limite, que é um valor bem próximo do primeiro quartil para esse conjunto de dados. Isso significa que em aproximadamente 25% dos dias, a vazões são inferiores a esse valor.  

```{r status-definicao}

# Define valor-limite
limite <- 1

# Testando o código

#Vazao <- c(12,15,20,16,10,9,8,7,12,25,43,34,22,21,20,19,18,17,25,34,55,43,14,13)
#index <- 1:length(Vazao)
#data <- seq(ymd('2012-04-01'),ymd('2012-04-24'), by = '1 day')
#Qd <- data.frame(index,data,Vazao)

## identifica dias em que vazão é inferior ao limite estabelecido
## e cria nova coluna no daaframe
Qd$status <- Qd$Vazao < limite
tibble(Qd)

```

Embora não seja possível visualizar nas primeiras 10 linhas da Tabela cima, a coluna `status` contém `FALSE` quando o dia é considerado **úmido** e `TRUE` quando o dia é considerado **seco**. E como pode ser visto, `status = NA` quando há falha nos dados de vazão. 

### Plotagem dos períodos secos e períodos úmidos

Com o que temos até aqui, o que não é muito, já é possível visualizar a ocorrência e o comprimento dos períodos secos e períodos úmidos ao longo da série histórica. 

Para isso, utilizaremos o `geom_tile` do pacote `ggplot2`.

```{r heatmap ggplot2, fig.width = 8, fig.height = 8}
## Plotagem dos períodos secos e úmidos

# Identifica o dia de início de cada mês para fins de plotagem
month_starts <- yday(as.Date('1978-01-01') %m+% months(0:11))

# Função para definir a mudança de ano
Year_break = function (...){
  function(x) {
    minx         = floor(min(x)) - 1;
    maxx         = ceiling(max(x)) + 1;
    major_breaks = seq(minx, maxx, by=1)
    return(major_breaks)
  }
}

# Definição da cor das letras na Figura
textcol <- "grey40"

# Inicia a plotagem
ggplot() +
  
  geom_tile(data = Qd,
            aes(x = yday(Data), y = year(Data), fill = status)) +
  
  # Plota linhas verticais no início de cada mês para facilitar visualização
  geom_vline(xintercept = month_starts,color = "white", size=0.5) +
  
  # Título da Figura e da legenda
  guides(fill=guide_legend(title="Status do período"))+
  labs(x="", y="", title="Períodos seco (Q < 1 m3/s) e úmido (Q > 1 m3/s)")+
 
   # Cores para seco, úmido e NA
  scale_fill_brewer(palette = "Pastel1",
                    breaks = c(FALSE,TRUE, NA), 
                    labels = c("Úmido", "Seco", "Falha")) +
  
  # Especificações dos eixos
  scale_x_continuous(name = '', breaks = month_starts, labels= month.abb, expand = c(0,0)) +
  scale_y_continuous(name = '', breaks = Year_break(), expand = c(0,0),trans = "reverse" ) +
  
  # Vários detalhes da plotagem
  theme_grey(base_size=10)+
  theme(legend.position="right", legend.direction="vertical",
        legend.title=element_text(colour=textcol),
        legend.margin=margin(grid::unit(0, "cm")),
        legend.text=element_text(colour=textcol, size=7, face="bold"),
        legend.key.height=grid::unit(0.8, "cm"),
        legend.key.width=grid::unit(0.4, "cm"),
        axis.text.x=element_text(size=10, colour=textcol),
        axis.text.y=element_text(vjust=0.2, colour=textcol),
        axis.ticks=element_line(size=0.4),
        plot.background=element_blank(),
        panel.border=element_blank(),
        plot.margin=margin(0.7, 0.4, 0.1, 0.2, "cm"),
        plot.title=element_text(colour=textcol, hjust=0, size=12, face="bold")
      )
```
Podemos observar que, de uma forma geral, os períodos **secos**, aqueles com dias consecutivos com vazão inferior a `r limite` m$^3$/s, ocorrem normalmente entre os meses de julho e novembro. 

Mas é também interessante notar que a partir do meio da década de 1990, pelo menos é essa a aimpressão que passa, essas vazões mais baixas se tornaram mais frequentes, com períodos secos mais extensos, com ocorrência também em dezembro e janeiro. 

### Frequência e extensão dos períodos secos (*dry spells*)

Agora que já temos uma boa noção de quando os períodos secos e úmidos ocorreram ao longo do período histórico, passemos para uma análise quantitativa um pouco mais detalhada. 

Iniciaremos esta nova etapa com uma descrição da frequência dos períodos secos com diferentes comprimentos. Podemos fazer a mesma coisa para os períodos **úmidos**, mas vamos nos limitar aqui nesta aula aos períodos **secos**.

Podemos iniciar esta etapa identificando os dias em que houve mudança de *status*, ou seja, quando o período passou de **seco** para **úmido** e vice-versa.  

Para isso, iremos comparar o *status* da vazão de um dia, com o *status* da vazão do dia seguinte. Se os *status* forem diferentes, significa que houve mudança de *status*. Óbvio, não? 

Mas existe um pequeno complicador nessa história, pois além dos *status* `TRUE` (**seco**) e `FALSE` (**úmido**), temos também o *status* `NA` (**Falha**). Para evitar possíveis complicações com o uso de `NA` nas funções a serem empregadas mais adiante, vamos substituir o `status = NA` no dataframe `Qd` por `status = -1`. 

Feita essa subtituição, utilizaremos a função `which`, em conjunto com um operador lógico que compara se os *status* de dois dias consecutivos são diferentes, para obter o índice de cada uma das mudanças que ocorreram na série histórica, como mostrado abaixo, 

```{r}
## identifica quando ocorre mudança de status na vazão 
## Qd$status = 0 (wet)
## Qd$status = 1 (dry)
## Qd$status = -1 (Falha)
n <- nrow(Qd)
i_NA <- which(is.na(Qd$status))
Qd$status[i_NA] <- -1
i_change <- c(which(Qd$status[1:n-1] != Qd$status[2:n]), n) 

```

Os `r formatC(length(i_change), format = "d")` valores contidos no vetor `i_change`, apresentados abaixo, indicam a última posição de cada um dos `r formatC(length(i_change), format = "d")` períodos contidos no histórico. Podemos ver, por exemplo, que o primeiro período se encerra na posição (dia) `r formatC(i_change[1],format = "d")` e o segundo na posição (dia) `r formatC(i_change[2],format = "d")`.   

```{r i-change, echo=FALSE}
i_change
```

Embora saibamos quando a mudança de *status* ocorre, ou seja, quando os períodos mudam, não sabemos ainda o *status* de cada uma dos períodos identificados.

Mas antes de determinar o tipo de período, podemos já calcular seus comprimentos. Para isso, acrescentamos o valor `0` como primeiro elemento do vetor `i_change` de modo que as diferenças de seus elementos consecutivos sejam iguais aos comprimentos dos períodos,

```{r comprimentos-spell}
## Determina o comprimento de cada período (seco, úmido ou NA)

l_spell <- diff(c(0, i_change))

```

O vetor `l_spell` armazena os comprimentos de todos os `r formatC(length(l_spell), format = "d")` períodos, como pode ser visto abaixo,

```{r l-spell, echo=FALSE, class.source = 'fold-hide'}
l_spell
```


Para realizar a identifcação do tipo de cada período, utilizaremos conjuntamente os índices de onde as mudanças ocorrem (`i_change`) e os respectivos *status*, armazenados na columa `Qd$status` do nosso `dataframe` `Qd`. 

Essa operação nos retorna um vetor com os seguintes possíveis valores: `-1, 0, 1`. O valor `-1` indica que o período em questão é de **falhas** apenas. Por outro lado, os valores `0` e`1` indicam, respectivamente, períodos **úmidos** e **secos**.

No nosso código abaixo, esses valores são armazenados no vetor `spell_type`. 

```{r spell-type}

## identifica se é um dry spell, wet spell ou período de falhas
## spell_type = TRUE: dry spell
## spell_type = FALSE: wet spell

spell_type <- Qd$status[i_change]
```

Podemos ver com base no elementos do vetor `spell_type`, apresentado abaxio, que para os dados que estamos trabalhando, temos um total de 400 períodos, sendo que o primeiro período está indicado como `r formatC(spell_type[1], format = "d")`, o que significa dizer que é um período de falhas.

```{r spell-type-print}
spell_type
```

Esse vetor `spell_type` é utilizado então para identificarmos os índices para cada tipo de período,

```{r indices-por-type}
## Identifica índices dos três tipos de períodos

i_dry <- which(spell_type == TRUE)
i_dry
i_wet <- which(spell_type == FALSE)
i_wet
i_falha <- which(spell_type == -1)
i_falha
```

Sabendo os índices associados a cada tipo de período, podemos relacionar com os valores de comprimentos de períodos armazenados no vetor `l_spell` e finalmente determinar os diversos comprimentos dos períodos secos, úmidos e de falhas. 

```{r}
## Extensão dos spells
l_dry <- l_spell[i_dry]
l_wet <- l_spell[i_wet]
l_falha <- l_spell[i_falha]

l_dry
l_wet
l_falha
```

Embora não seja muito fácil de visualizar, creio que valha a pena tentar entender os números apresentados acima, que representam os comprimentos dos `r length(l_dry)` períodos **secos**, `r length(l_wet)` períodos **úmidos** e `r length(l_falha)` períodos de **falhas**.

Para deixar registrado os achados, vamos criar um `dataframe` com os resultados relacionados aos períodos secos. O nosso `dataframe` será denominado `dry_spell` e conterá as seguintes colunas: `ano`, `data_inicio_dry`, e `comprimento`.

```{r construcao-dataframe-dry-spells}
## Construção de um novo dataframe com os dados de dry spell
data_inicio_dry <- Qd$Data[i_change[i_dry]] - l_dry
dry_spell <- data.frame(ano = year(Qd$Data[i_change[i_dry]]),
                        data_inicio_dry = Qd$Data[i_change[i_dry]],
                        comprimento = l_dry)
tibble(dry_spell)
```
  
```{r plot-hist-dry-spell}
ggplot(dry_spell, aes(x=comprimento)) + 
  geom_density()

```

### Cálculo e análise do volume de deficit

### Identificar veranicos




### 
## Fontes de consulta

- O site [Visualizing hydrologic data](https://tonyladson.wordpress.com/2018/12/02/visualising-hydrologic-data/), escrito por [Tony Ladson](https://tonyladson.wordpress.com/tests/), além de conter exemplos interessantes de plotagem em Hidrologia, disponibiliza os códigos usados na linguagem **R**.

  - [Curva de permanência (Flow duration curve)](https://tonyladson.wordpress.com/2018/12/04/flow-duration-curves/)
  - [Momento do ano das máximas anuais](https://tonyladson.wordpress.com/2016/06/01/what-time-of-year-does-it-flood/)
