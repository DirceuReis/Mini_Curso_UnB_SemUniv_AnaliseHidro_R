{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:43-03:00"
    },
    {
      "path": "colaboradores.html",
      "title": "Colaboradores",
      "description": "Exclusivo para a Semana Universitária",
      "author": [],
      "contents": "\r\n\r\nContents\r\nThiago Lappicy\r\nSaulo Aires de Souza\r\nLuiz Felipe Pereira de\r\nBrito\r\n\r\nApesar deste curso ser uma iniciativa do grupo Água e Modelagem,\r\ncontamos com a participação exclusiva para a Semana Universtária da UnB\r\nde dois integrantes:\r\nThiago Lappicy\r\nThiago Lappicy é aluno de mestrado do Programa de Engneharia Civil e\r\nAmbiental da Universidade de Brasília (PTARH/UnB).\r\nSaulo Aires de Souza\r\nSaulo é Coordenador de Estudos Hidrológicos da Agência Nacional de\r\nÁguas\r\nLuiz Felipe Pereira de Brito\r\nLuiz Felipe é aluno do curso de Engenharia Ambiental da Universidade\r\nde Brasília\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:44-03:00"
    },
    {
      "path": "conc_basic_R.html",
      "title": "Linguagem R",
      "description": "Conceitos básicos",
      "author": [],
      "contents": "\r\n\r\nContents\r\nVisão geral\r\nFunções\r\nPacotes\r\n\r\nVisão geral\r\nFunções\r\nPacotes\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:45-03:00"
    },
    {
      "path": "data_explore.html",
      "title": "Análise exploratória dos dados",
      "description": "Como obter uma visão geral dos dados",
      "author": [],
      "contents": "\r\n\r\nContents\r\nPacotes\r\nCarcaterização numérica\r\nCaracterização gráfica\r\n\r\nPacotes\r\nCarcaterização numérica\r\nCaracterização gráfica\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:46-03:00"
    },
    {
      "path": "data_manip.html",
      "title": "Maniplação dos dados",
      "description": "Como organizar para facilitar as análises",
      "author": [],
      "contents": "\r\n\r\nContents\r\nPacotes\r\nBla bla bla\r\n\r\nPacotes\r\nBla bla bla\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:46-03:00"
    },
    {
      "path": "frequency_analysis.html",
      "title": "Análise de frequência de cheias",
      "description": "Exemplo com dados reais",
      "author": [],
      "contents": "\r\n\r\nContents\r\nObjetivos da atividade\r\nPassos a serem\r\nexecutados\r\nVisualização dos dados\r\nobservados\r\nEscolha da estação\r\nfluviométrica\r\nSeleção das vazões\r\nmáximas anuais\r\nCálculo das posições de\r\nplotagem\r\nConstrução da\r\ncurva de frequência amostral\r\n\r\nInferência\r\nCálculo dos momentos-L\r\nDiagrama de momentos-L\r\nEstimativa dos\r\nparâmetros da distribuição\r\nCálculo dos quantis de\r\ncheia\r\n\r\nConstrução da curva de\r\nfrequência\r\nDescrição\r\ndas incertezas (intervalo de confiança)\r\nCurva de frequência\r\nfinal\r\nDetalhes técnicos\r\nDistribuição de\r\nprobabilidades\r\n\r\n\r\nObjetivos da atividade\r\nO objetivo desta atividade é realizar uma análise de frequência de\r\ncheias a nível local. Isso significa que iremos relacionar a magnitude\r\ndas vazões máximas anuais com a probabilidade da mesma ser excedida. A\r\nanálise a nível local siginifca que utilizaremos apenas as informações\r\nde vazão observadas na estação fluviométrica de interesse, sem fazer uso\r\nde informações de vaões que teham acontecido na região. Além da relação\r\nentre a magnitude da vazão e a probabilidade de excedência, é importante\r\nsaber estimar também o grau de incertezas nessas estimativas. As\r\nincertezas são usualmente reprsentadas por intervalos de confiança.\r\nAlém de calcular essas quantidades, normalmente a curva de\r\nfrequência, e suas respectivas incertezas, são representadas\r\ngraficamente, como apresentado na figura abaixo, que mostra os\r\nresultados para um estudo de cheias numa seção do Rio Salado, localizada\r\nna província de Santa Fé, na Argentina, onde em 2003 ocorreu o\r\nrompimento de um dique que resultou em mortes e elevados prejuízos.\r\nContruiremos aqui uma figura semephante, onde no eixo-x temos o tempo\r\nde recorrência e no eixo-y a magnitude das vazões máximas anuais. A\r\nlinha cheia em vermelho representa o valor esperado dos valores de vazão\r\nem função do tempo de recorrência, enquanto a linhas tracejadas\r\nrepresentam os intervalos de confiança de 95%, ilustrando as incertezas\r\nenvolvidas nessas estimativas. Os círculos azuis escuros representam as\r\nvazões máximas anunias registradas no passado, enquanto o círculo azul\r\nclaro mostra a cheia destruidora de 2003.\r\n\r\n\r\n\r\n(#fig:curva_freq)Curva de frequência do cheias do Rio Salado, na\r\nArgentina.\r\n\r\n\r\n\r\nPassos a serem executados\r\nVisualizar os dados\r\nEscolha da estação fluviométrica\r\nObtenção da série de máximos anuais\r\nCálculo das posições de plotagem\r\nConstrução de figura utilizando valores amostrais apenas\r\n\r\nInferência\r\nCálculo dos momentos-L para fins de verificação da distribuição\r\nteórica de probabilidades\r\nPlotagem do diagrama de momentos-L das distribuições teóricas\r\nAjuste dos parâmetros da distribuição teórica de probabilidades\r\nLognormal\r\nGeneralizada de valores extremos\r\n\r\nCálculo dos quantis de cheia\r\n\r\nCurva de frequência sem incertezas\r\nEstimativa dos intervalos de confiança para a distribuição\r\nLognormal\r\nCurva de frequência com intervalos de confiança\r\nVisualização dos dados\r\nobservados\r\nEscolha da estação\r\nfluviométrica\r\nSeleção das vazões máximas\r\nanuais\r\nAqui, nós faremos uso de uma banco de dados criado pelo Saulo Aires\r\nde Souza em sua tese de doutorado. Utilizaremos um arquivo que contém as\r\nséries de máximos anuais de 124 estações fluvométricas localizadas na\r\nbacia do Rio São Francisco (https://doi.org/10.5281/zenodo.6551909).\r\nO código abaixo lê o arquivo e armazena os anos e os valores das\r\nvazões máximas anuais da primeira estação do banco de dados num\r\ndataframe chamado flows. Nós usamos a função\r\ntibble para mostrar uma parte das informações contidas\r\nnesse dataframe.\r\n\r\n\r\n\r\n\r\n\r\ndata <- read.delim(\"dados/qx1d_RH SFR.dat\",sep=\";\",header=FALSE,na.strings = \"null\",skip=12)\r\n#as.Date(df$Date, format =  \"%m/%d/%Y %H:%M:%S\")\r\n#year <- as.Date(data[-1,1], format=\"%Y\")\r\nyear <- as.numeric(data[-1,1])\r\nQ <- as.numeric(data[-1,2])\r\ndf <- data.frame(year, Q)\r\n\r\n# find NA's and remove from dataframe\r\nflows <- na.omit(df) \r\ntibble(flows)\r\n\r\n\r\n# A tibble: 70 × 2\r\n    year     Q\r\n   <dbl> <dbl>\r\n 1  1939 112. \r\n 2  1940  34.2\r\n 3  1941 107. \r\n 4  1942 102. \r\n 5  1951 159. \r\n 6  1952  44.0\r\n 7  1953  59.2\r\n 8  1954  50.3\r\n 9  1955  96.2\r\n10  1956 107. \r\n# … with 60 more rows\r\n\r\nÉ sempre importante visualizar a série de máximos anuais. Para isso,\r\nutilizamos\r\n\r\n\r\nlibrary(ggplot2)\r\n ggplot(flows,aes(x=year, y=Q)) +\r\n    geom_point() +\r\n    geom_line()\r\n\r\n\r\n\r\n#lines(pressure$temperature, pressure$pressure/2, col = \"red\")\r\n\r\n\r\n\r\nCálculo das posições de\r\nplotagem\r\nConstrução da curva\r\nde frequência amostral\r\nInferência\r\nCálculo dos momentos-L\r\nDiagrama de momentos-L\r\nEstimativa dos\r\nparâmetros da distribuição\r\nCálculo dos quantis de cheia\r\nConstrução da curva de\r\nfrequência\r\nDescrição das\r\nincertezas (intervalo de confiança)\r\nCurva de frequência final\r\nDetalhes técnicos\r\nDistribuição de\r\nprobabilidades\r\nPara que servem?\r\nO uso de uma distribuição teórica de probabilidades se justifica por\r\ntrês motivos,\r\npermite a extrapolação da curva, ou seja, torna possível a\r\nestimativa de uma vazão com 50 anos tempo de retorno mesmo quando temos\r\napenas 20 anos de dados;\r\npode ser utilizada como um interpolador de quantis de cheia, já que\r\no uso da frequência amostral só permite estimar quantis para um número\r\ndiscreto, e nem sempre desejado, de períodos de retorno.\r\né uma maneira de armazenar as infomações relevantes da série de\r\nmáximos de maneira compacta, visto que basta guardar o valor dos\r\nparâmetro da distribuição para obter qualquer quantil de cheia que se\r\ntenha interesse.\r\nQuais são as\r\ndistribuições mais usadas?\r\nComo avaliar a\r\ndistribuição mais indicada?\r\nAjuste dos parâmetros da\r\ndistribuição\r\nEstimativa dos quantis de\r\ncheia\r\nDescrição das incertezas\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:52-03:00"
    },
    {
      "path": "get_data.html",
      "title": "Obtenção de dados na web",
      "description": "Conceitos básicos",
      "author": [],
      "contents": "\r\n\r\nContents\r\nRepositório de dados\r\nObtenção via webservice\r\nLista das Estações\r\nTelemétricas da ANA\r\nDados\r\nHidrometeorológicos da ANA\r\n\r\nRepositório de dados\r\nObtenção via webservice\r\nColetar informação da internet, também conhecido como “webscraping”,\r\né algo muito comum hoje em dia. A ANA (Agência Nacional de Águas e\r\nSaneamento Básico), o ONS (Operador Nacional do Sistema Elétrico) e\r\nmuitos outros disponibilizam alguns de seus dados via o webservice.\r\nIsso, no fundo, é apenas um site contendo esses dados. Porém isso tudo é\r\norganizados de uma maneira bem específica. Portanto, a primeira coisa\r\nque precisa-se saber para utilizar um webservice é saber como essa\r\norganização é feita!\r\nNo caso do webservice da ANA, tudo isso está disponível no url: http://telemetriaws1.ana.gov.br/ServiceANA.asmx Nele\r\nvemos todas as informações disponíveis, tais como “dados\r\nhidrometeorológicos”, “dados hidrometeorológicos gerais”, “lista de\r\nestações telemétricas”, “Cotas”, “inventário”, “rios”, “série histórica”\r\ne outros. Existe nesse site inclusive um arquivo em .pdf que fala melhor\r\nsobre o sistema como um todo e o que pode-se achar dentro dele! Isso\r\nestá no url abaixo. Esse arquivo é essencial para entendermos como os\r\ndados estão disponíveis e como podemos acessar eles. http://telemetriaws1.ana.gov.br/Telemetria1ws.pdf\r\nDescobrimos então que os dados da ANA estão disponibilizados no\r\nformato XML (“Extended Markup Language”) e com isso faremos os próximos\r\npassos. Não entraremos muito a fundo nesse formato e suas\r\ncaracterísticas, porém para quem quiser aprender mais sobre webscraping\r\nvale a pena dar uma olhada.\r\nLista das Estações\r\nTelemétricas da ANA\r\nComeçaremos acessando os dados das estações telemétricas desse\r\nsistema. No próprio site é mostrado que é preciso de dois parâmetros\r\npara pesquisas as estações, um chamado de “statusEstacoes” que pode ser\r\n0 (ativo) ou 1 (manutenção) e outro parâmetro chamado de “Origem” que\r\npode variar entre 0 e 5. No arquivo .pdf citado acima, é comentado que\r\nse deixarmos o “statusEstacoes” em branco, serão retornadas as\r\ninformações de todas as estações do sistema (o que queremos!). Assim, se\r\ncolocarmos no nosso navegador o seguinte url: http://telemetriaws1.ana.gov.br/ServiceANA.asmx/ListaEstacoesTelemetricas?statusEstacoes=&origem=,\r\nteremos acesso ao arquivo XML com a informação de todas as estações\r\ntelemétricas.\r\n(queria botar uma foto aqui de como fica o site, depois eu vejo como\r\nfazer certinho no rmarkdown)\r\nExemplo abaixo de como incluir uma Figura. Há várias maneras de fazer\r\nisso, essa de baixo é apenas uma delas.\r\n\r\n\r\n\r\n(#fig:curva_freq)Curva de frequência do cheias do Rio Salado, na\r\nArgentina.\r\n\r\n\r\n\r\nPara abrirmos esse mesmo formato no RStudio, utilizamos uma função do\r\npacote “XML” chamada xmlParse(). Essa função irá apenas ler um arquivo\r\ndo tipo XML e vai gerar uma estrutura no R similar ao que aparece na\r\nimagem acima (formato de “árvore”). A função toma como argumento\r\nobrigatório o url a ser utilizado e um argumento opcional é a\r\ncodificação do arquivo (do inglês encoding). Usualmente no Brasil\r\nutilizamos o “UTF-8” para poder utilizar nossos acentos (mas lembre-se\r\nque essa parte é um outro mundo no R e não entraremos com maiores\r\ndetalhamentos).\r\n\r\n\r\nstatus_codigo <- \"1\"\r\norigem_codigo <- \"78000000\"\r\n\r\nurl_base <- paste0(\"http://telemetriaws1.ana.gov.br/ServiceANA.asmx/ListaEstacoesTelemetricas?statusEstacoes=\", status_codigo, \"&origem=\", origem_codigo)\r\nurl_parse <- XML::xmlParse(url_base, encoding = \"UTF-8\")\r\n\r\n\r\n\r\nOlha o nosso código um pouco. Percebe que invés de digitar\r\ndiretamente o url para acesso, quebramos ele em várias partes e juntamos\r\ncom a função paste0(). Fizemos isso para ficar mais fácil de mudar algo\r\ndepois. Caso quisermos utilizar outro valor em “statusEstacoes” ou em\r\n“Origem”, basta mudarmos os objetos criados e o resto do código continua\r\nigual! Ao chamar o url_parse no console, verá uma imagem similar ao site\r\nquando abrimos o url.\r\nPara puxar agora as informações dessas estações, precisamos entender\r\nmelhor o arquivo original no formato XML. De maneira resumida, arquivos\r\nno formato XML ou HTML possuem estruturas que são definidas entre “<\r\n>”. Ao mexer no url que nos dá todas as estações, percebe-se que\r\ntodos os dados de cada estação são precedidos por um elemento chamado\r\n“Table” (dentro do “<>”). Porém, queremos os nodes que estão\r\nassociados a esses “Tables” (tabelas). Para isso, samos a função\r\ngetNodeSet(). Com os argumentos sendo o objeto depois de ter feito um\r\nxmlParse() e o “//Table” (lembrar de colocar essas duas barras)\r\n(aqui depois vou botar outra imagem, mostrando isso melhor).\r\nA próxima etapa agora é transformar esse arquivo em algo que estamos\r\nmais acostumados a mexer dentro do R. Boas opções são dataframes e\r\nlistas. Como não aprendemos a mexer muito com listas, vamos transformar\r\nnosso objeto em um dataframe. Para isso utilizamos a função\r\nxmlToDataFrame().\r\n\r\n\r\ncadastro_estacoes <- xmlToDataFrame(nodes = nodes_doc)\r\n\r\n\r\n\r\nAgora podemos fazer as manipulações que já aprendemos anteriormente\r\n(com dataframe ficou fácil!). Por exemplo, se quisermos selecionar\r\napenas as estações de Brasília, escrevemos o código abaixo. O\r\n“Municipio-UF” é apenas uma das colunas do dataframe, podemos filtrar\r\ncom base em qualquer outra também.\r\n\r\n\r\nestacoes_bsb <- filter(cadastro_estacoes, `Municipio-UF` == \"BRASÍLIA-DF\")\r\n\r\n\r\n\r\nLembrando que isso tudo nos dá apenas a lista com informações sobre\r\nas estações telemétricas. Para de fato termos acesso aos dados dessas\r\nestações, precisamos acessar outro url e fazer mais alguns códigos!\r\nIdealmente, se a gente quiser ficar sempre puxando diferentes\r\ninformações e não ficar precisando rodar linha por linha de código,\r\npodemos juntar tudo isso em uma função. Para a nossa função, deixaremos\r\no processo um pouco melhor. Primeiro definiremos que a função precisa de\r\n3 parâmetros (o status da estação, a origem e qual Unidade Federativa do\r\nBrasil queremos). Após puxar os dados em XML e transformar tudo em um\r\ndataframe, fazemos aqui algo novo - criamos uma coluna chamada “UF”\r\ncontendo apenas as últimas duas letras do Município (isos porque no\r\narquivo original, as duas últimas letras são as siglas da UF).\r\n\r\n\r\nANA_info <- function(status_codigo = \"\",\r\n                     origem_codigo = \"\",\r\n                     UF_fun = \"DF\"){\r\n\r\n  # Essas etapas foram vistas anteriormente\r\n  url_base <- paste0(\"http://telemetriaws1.ana.gov.br/ServiceANA.asmx/ListaEstacoesTelemetricas?\",\r\n                     \"statusEstacoes=\", status_codigo,\r\n                     \"&origem=\", origem_codigo)\r\n  url_parse <- XML::xmlParse(url_base, encoding = \"UTF-8\")\r\n  nodes_doc <- XML::getNodeSet(url_parse, \"//Table\")\r\n  cadastro_estacoes <- XML::xmlToDataFrame(nodes = nodes_doc)\r\n  \r\n  # Aqui criamos uma coluna no dataframe apenas com nomes das UFs\r\n  cadastro_estacoes$UF <- substr(cadastro_estacoes$`Municipio-UF`,\r\n                                 nchar(cadastro_estacoes$`Municipio-UF`) - 1,\r\n                                 nchar(cadastro_estacoes$`Municipio-UF`))\r\n                                 \r\n  estacoes_UF <- dplyr::filter(cadastro_estacoes, `UF` == UF_fun)\r\n\r\n  return(estacoes_UF)\r\n}\r\n\r\n\r\n\r\nDados Hidrometeorológicos da\r\nANA\r\nPara acessar os dados hidrometeorológicos nesse webservice, temos\r\noutro url: http://telemetriaws1.ana.gov.br/ServiceANA.asmx?op=DadosHidrometeorologicos.\r\nNele, vemos que são necessárias agora três parâmetros para fazermos uma\r\nbusca: o “codEstacao” (que a gente pegou na parte anterior!), a\r\n“dataInicio” e a “dataFim”. Do mesmo jeito de antes, vamos definir um\r\nobjeto para cada parâmetro e depois criar um url baseado nesses\r\nparâmetros. Em seguida fazemos um xmlParse() e pegamos as informações\r\ncontidas nos nodes com o getNodeSet(). Por último, transformamos isso em\r\num dataframe. Dessa vez, podemos fazer a função direto ja!\r\n\r\n\r\ndados_ANA <- function(cod_estacao = \"\",\r\n                      data_inicio = \"01/01/2020\",\r\n                      data_fim = Sys.Date()){\r\n\r\n  # Puxar dados do url e transformar em dataframe\r\n  url_base <- paste0(\"http://telemetriaws1.ana.gov.br/ServiceANA.asmx/DadosHidrometeorologicos?\",\r\n                     \"codEstacao=\", cod_estacao,\r\n                     \"&dataInicio=\", data_inicio,\r\n                     \"&dataFim=\", data_fim)\r\n  url_parse <- XML::xmlParse(url_base, encoding = \"UTF-8\")\r\n  node_doc <- XML::getNodeSet(url_parse, \"//DadosHidrometereologicos\")\r\n  dados_estacao <- xmlToDataFrame(nodes = node_doc)\r\n  \r\n  return(dados_estacao)\r\n}\r\n\r\n# Rodar a função para a estação da FAL\r\ndados_FAL <- fun_puxad_dados_ANA(cod_estacao = 60478482)\r\n\r\n\r\n\r\nAo abrir esses dados_FAL, a gente percebe um “problema”. A data e a\r\nhora estão na mesma coluna e idealmente queremos deixar em colunas\r\nseparadas (uma contendo a data e outra contendo as horas). Então iremos\r\nadicionar dentro da nossa função, mais um comando para fazer essa\r\nseparação. Um jeito simples (mas não o único) de fazer isso é\r\nselecionando os primeiros 10 caracteres como sendo os de data e os\r\núltimos 8 como sendo de hora - porque a data sempre vai estar no formato\r\n“dia/mes/ano” e o horário em “hora:minuto:segundo”. Podemos também\r\nreorganizar as colunas do jeito que quisermos. Abaixo está essa nova\r\nfunção mais organizada. Chamamos novamente ela para rodar a estação da\r\nFAL.\r\n\r\n\r\ndados_ANA <- function(cod_estacao = \"\",\r\n                      data_inicio = \"01/01/2020\",\r\n                      data_fim = Sys.Date()){\r\n\r\n  # Puxar dados do url e transformar em dataframe\r\n  url_base <- paste0(\"http://telemetriaws1.ana.gov.br/ServiceANA.asmx/DadosHidrometeorologicos?\",\r\n                     \"codEstacao=\", cod_estacao,\r\n                     \"&dataInicio=\", data_inicio,\r\n                     \"&dataFim=\", data_fim)\r\n  url_parse <- XML::xmlParse(url_base, encoding = \"UTF-8\")\r\n  node_doc <- XML::getNodeSet(url_parse, \"//DadosHidrometereologicos\")\r\n  dados_estacao <- XML::xmlToDataFrame(nodes = node_doc)\r\n  \r\n  # Separar data e hora\r\n  dados_estacao$Data <- substr(dados_estacao$DataHora, 1, 10)\r\n  dados_estacao$Hora <- substr(dados_estacao$DataHora, 12, 19)\r\n\r\n  # Re-organizar a ordem das colunas do dataframe dados_estacao\r\n  dados_estacao <- dados_estacao[,c(1, 6, 7, 3, 4, 5)]\r\n  \r\n  return(dados_estacao)\r\n}\r\n\r\n# Rodar a função para a estação da FAL\r\ndados_FAL <- dados_ANA(cod_estacao = 60478482)\r\n\r\n\r\n\r\nAqui rodamos a função apenas para uma estação. Mas se quisermos rodar\r\npara várias estações, basta utilizar um loop (for) ou até mesmo a função\r\nlapply do R (mais rápido!). ## Outras formas\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:56-03:00"
    },
    {
      "path": "index.html",
      "title": "Obtenção, manipulação e análise de dados hidrológicos com R: uma introdução para iniciantes",
      "description": "Uma iniciativa do grupo [Água e Modelagem](https://aguaemodelagem.wordpress.com) para a Semana Universitária da Universidade de Brasília de 2022\n",
      "author": [
        {
          "name": "Dirceu S. Reis Jr.",
          "url": "https://github.com/DirceuReis"
        },
        {
          "name": "Francisco Eustáquio Oliveira e Silva",
          "url": "https://github.com/fcoeustaquio"
        },
        {
          "name": "Pedro Luis Borges Chaffe",
          "url": "https://github.com/fcoeustaquio"
        },
        {
          "name": "Wilson dos Santos Fernandes",
          "url": "https://github.com/wsf-ehr"
        },
        {
          "name": "Thiago Lappicy",
          "url": "https://github.com/rich-iannone"
        },
        {
          "name": "Saulo AIres de Souza",
          "url": {}
        },
        {
          "name": "Luiz Felipe Pereira de Brito",
          "url": {}
        }
      ],
      "contents": "\r\n\r\nContents\r\nApresentação\r\nDatas e local do curso\r\nAntes do curso\r\nTópicos (em construção)\r\nNoções de R\r\nObtenção dos dados\r\nManipulação dos dados\r\nAnálise exploratória dos\r\ndados\r\nAnálise de frequência de\r\ncheias\r\n\r\n\r\nApresentação\r\nEste é um curso introdutório sobre a linguagem R para aqueles\r\ninteressados em realizar análises hidrológicas. Será oferecido pela\r\nprimeira vez durante a Semana\r\nUniversitária da Universidade de Brasília, que acontecerá entre os\r\ndias 29/08 e 02/09 de 2022.\r\nDurante o curso, os alunos irão aprender como utilizar a linguagem R\r\npara executar um conjunto de atividades que permitirão realizar uma\r\nanálise de frequência de cheias para uma estação fluviométrica, cujos\r\ndados serão automaticamente obtidos do webservice da Agência Nacional de\r\nÁguas. Ao final do curso, os alunos terão finalizado um estudo que\r\npermitirá relacionar a magnitude das vazões máximas anuais com sua\r\nprobabilidade de excedência, relação primoridal para dimensionameno de\r\ndiversas estrutaras de engenharia, gestão do risco de cheias e para o\r\noredenamento do uso e ocupação do solo.\r\nEste curso é o primeiro de um conjunto maior de cursos que estão\r\nsendo elaborados pelos seguintes professores do blog Água e Modelagem:\r\nDirceu S. Reis Jr.\r\nFrancisco Eustáquio\r\nPedro Chaffe\r\nWilson Fernandes\r\nDatas e local do curso\r\nO curso será dado na Sala 5 do Laboratório Central de Computação\r\nCientífica da Faculdade de Tecnologia da Universidade de Brasília (LCCC\r\nULEG-FT), que fica localizado no prédio da Unidade de Laboratórios de\r\nEnsino de Graduação da Faculdade de Tecnologia (ULEG/FT).\r\nO curso será dividido em 5 aulas de 2 horas cada, totalizando 10\r\nhoras. As aulas serão dadas nos seguintes horários:\r\n29/08 a 01/09 das 8h00 às 10h00\r\n02/09 das 12h00 às 14h00.\r\nAntes do curso\r\nIncluiremos aqui um tutorial de como instalar o R, RStudio e os\r\ndiversos pacotes que serão utilizados no curso.\r\nR e RStudio\r\nPacotes\r\ntydiverse\r\n\r\nTópicos (em construção)\r\nNoções de R\r\nCriação de objetos e operações matemáticas básicas\r\nAbertura de arquivos de várias fontes (csv, excel, binário etc)\r\nDiscussão de Como lidar com a presença de “NA” no R com exemplos de\r\noperações\r\nApresentação de alguns pacotes (tidyverse: dplyr, ggplot2,\r\nlubridate)\r\nObtenção dos dados\r\nObtenção a partir de diversas fontes de informação\r\nAGência Nacional de Águas e Saneamento Básico (ANA)\r\nOperador Nacional do Sistema Elétrico (ONS)\r\nBases da dados internacionais\r\n\r\nProcedimentos para pré-selecionar estações\r\ncom base num Shapefile de uma bacia\r\n(IMPORTANTE: ir atrá disso) código Thiago: lat-lon -> trecho de\r\nrio -> trechos de montante -> estações flu\r\n\r\nObtenção de informações com bae em diferentes forms de filtros\r\n% falhas no ano\r\nnúmero mínimo de anos sem falhas]\r\nnúmero mínimo de anos sem falhas consecutivas\r\noutros\r\n\r\nManipulação dos dados\r\nReorganizar dados dependendo das especificidades do que se quer\r\nfazer\r\nGerar séries diárias, mensais e anuais (considerando ano\r\nhidrológico)\r\nGerar séries de Q7\r\nGerar séries de máximos anuais\r\nGerar séries acima de um determinado threshold (para análise\r\nPDS)\r\nDeterminação de veranicos (extensão e frequência) nos dados de\r\nchuva\r\noutros?\r\nAnálise exploratória dos\r\ndados\r\nRepresentação gráfica oriundas de um conjunto de estações\r\nem um mapa\r\nem um gráfico (e.g., boxplot)\r\n\r\nRepresentação gráfica de uma única estação\r\nRepresentação numérica\r\nMédia\r\ndesvio-padrão\r\ncorrelação temporal\r\ncorrelação espacial\r\n\r\nAnálise de frequência de\r\ncheias\r\nPosição de plotagem\r\nA distribuição de probabilidades\r\nAjuste da distribuição\r\nValores dos parâmetros\r\nDeterminação dos quantis de cheia\r\nDeterminação dos intervalos que descevem as incertezas na\r\nestimativa\r\nPlotagem\r\ncurva de frequência (Tr vs Q)\r\n\r\nTabelas com resutados\r\n\r\n\r\n\r\n",
      "last_modified": "2022-06-24T14:09:56-03:00"
    }
  ],
  "collections": []
}
